---
title: Private clusters
description: Learn how to manage private clusters in Giant Swarm. A private cluster lets you limit the Kubernetes API access and at the same time control egress traffic of your workload using a proxy.
weight: 35
menu:
  main:
    parent: advanced
user_questions:
- How do I make a workload cluster private?
owner:
  - https://github.com/orgs/giantswarm/teams/team-phoenix
last_review_date: 2023-06-13
---

By default, Giant Swarm clusters expose the Kubernetes API endpoint publicly and the cluster workloads have internet access. In the following sections, we will explain different options to restrict inbound access to API or outbound connectivity to the internet within the clusters.

**Note**: You can skip this article unless you plan on creating clusters with strictly-limited networking.

The following products offer private cluster features:

- {{% impl_title "capa_ec2" %}}
- {{% impl_title "capz_vms" %}}

Private clusters have special requirements:

- Since a private workload cluster still has to be reachable by the management cluster, there must be networking peering between the two. This means that the IP ranges must not overlap.
- Access to the Kubernetes API can be restricted to an internal network. It should then be reachable both by you as customer, and by Giant Swarm for support purposes. For example, a VPN can be used.
- An HTTP proxy can be used to restrict which exact domains can be accessed at all. In this case, a precise configuration is essential or else the new cluster will not be able to fetch container images or reach other important resources such as internal communication to the Kubernetes API.

To get everything set up correctly, please get in contact with Giant Swarm. We will help creating and supporting your desired private cluster configuration within your network architecture.

At the moment, we have these [`kubectl gs template cluster` command line options]({{< relref "/use-the-api/kubectl-gs/template-cluster" >}}) to configure access to/from the cluster:

- `--cluster-type`
- `--vpc-mode`
- `--dns-mode`
- `--api-mode`
- `--http-proxy`/`--https-proxy`

We have a few provider-specific hints:

{{< tabs >}}
{{< tab id="private-cluster-capz-azure-vms" for-impl="capz_vms">}}

As getting the correct CIDR depend on the installation, please get in contact with your platform team to check for the next CIDR range to use. This step might become obsolete once a dedicated IPAM operator got implemented for private Azure clusters.

The below command will list all clusters for a given management cluster, their used CIDRs and the API server type (useful to differentiate between public and private/internal clusters):

```text
$ kubectl get azurecluster -A -o=custom-columns='NAMESPACE:.metadata.namespace,CLUSTER-NAME:.metadata.name,HOST-CIDR:.spec.networkSpec.vnet.cidrBlocks,CONTROLPLANE-CIDR:.spec.networkSpec.subnets[?(@.role=="control-plane")].cidrBlocks,WORKERS-CIDR:.spec.networkSpec.subnets[?(@.role=="node")].cidrBlocks,APISERVER-TYPE:.spec.networkSpec.apiServerLB.type'

NAMESPACE           CLUSTER-NAME   HOST-CIDR         CONTROLPLANE-CIDR   WORKERS-CIDR      APISERVER-TYPE
org-giantswarm      glippy         [10.223.0.0/24]   [10.223.0.128/26]   [10.223.0.0/25]   Public
org-multi-project   jrp45          [10.0.0.0/16]     [10.0.0.0/20]       [10.0.16.0/20]    Public
org-observability   ytc82          [10.223.2.0/24]   [10.223.2.128/27]   [10.223.2.0/25]   Internal
```

In the example output, the next usable CIDR range is `10.223.3.0/24` and therefore the cluster configuration will look like:

```yaml
# filename: cluster-private-config.yaml
metadata:
  name: bzm29
  organization: observability
providerSpecific:
  location: westeurope
  subscriptionId: 6b1f6e4a-6d0e-4aa4-9a5a-fbaca65a4711
connectivity:
  network:
    controlPlane:
      cidr: 10.223.3.128/26
    hostCidr: 10.223.3.0/24
    mode: private
    podCidr: 192.168.0.0/16
    serviceCidr: 172.31.0.0/16
    workers:
      cidr: 10.223.3.0/25
```

This will create a workload cluster in the subscription `6b1f6e4a-6d0e-4aa4-9a5a-fbaca65a4711` in Azure region `westeurope`.

As all default apps are bundled in `default-apps-azure`, its basic configuration must be also given:

```yaml
# filename: default-apps-azure-config.yaml
clusterName: "bzm29"
organization: "observability"
```

The cluster template can now be generated by running:

```sh
kubectl gs template cluster --provider capz --cluster-config cluster-private-config.yaml --default-app-config default-apps-azure-config.yaml --output cluster.yaml
```

{{< /tab >}}
{{< /tabs >}}
