import sys
from datetime import datetime
from pprint import pprint
from yaml import load, dump, CLoader, CDumper
from github import Github
from github.GithubException import UnknownObjectException
from os import path, makedirs
import re

print("script.py arguments: %s" % sys.argv)

CONFIG_PATH = sys.argv[1]

# Target path for generated content
CONTENT_PATH = sys.argv[2]

GITHUB_TOKEN = sys.argv[3]


RELEASES_REPO = 'giantswarm/releases'

def get_releases(client, repo_shortname):
    """
    Yields all Github releases in the given repository
    """
    repo = client.get_repo(repo_shortname)

    for release in repo.get_releases():
        # skip unpublished releases
        if release.published_at is None:
            continue

        yield {
            'repository': repo_shortname,
            'version_tag': release.tag_name,
            'date': release.published_at,
            'description': release.body,
            'url': release.html_url,
        }

def get_changelog_file(client, repo_shortname):
    repo = client.get_repo(repo_shortname)
    try:
        remote_file = repo.get_contents('CHANGELOG.md')
        return remote_file.decoded_content.decode('utf-8')
    except UnknownObjectException:
        return None

def parse_changelog(body, repo_shortname):
    # Cut off the link reference at the end
    (good, bad) = body.split("[Unreleased]: ", maxsplit=1)
    
    # Create chunks based on level 2 headlines
    chunks = re.split(r'\n##\s+', good, flags=re.M)

    # Get rid of some bad chunks
    for chunk in chunks:
        lines = re.split(r'\n+', chunk, flags=re.M)
        
        if len(lines) < 2:
            continue
        if lines[0].startswith('[Unreleased]'):
            continue
        if not lines[0].startswith('['):
            continue
        
        # First line must start with semantic version number in square brackets
        match = re.match(r'^\[([^\.]+)\.([^\.]+)\.([^\]]+)\]', lines[0])
        if match is None:
            continue
        version = f'{match.group(1)}.{match.group(2)}.{match.group(3)}'

        anchor = lines[0].replace(' ', '-').replace('.', '').replace('[', '').replace(']', '')

        url = f'https://github.com/{repo_shortname}/blob/master/CHANGELOG.md#{anchor}'

        release = {
            'description': '\n'.join(lines[1:]).strip(),
            'url': url,
        }

        yield (version, release)


def normalize_version(v):
    """
    Removes a 'v' prefix from the version string
    """
    if v.startswith('v'):
        return v[1:]
    return v

def generate_release_file(repo_shortname, repo_config, release):
    """
    Write a release file with YAML front matter and Markdown body
    """
    org, slug = repo_shortname.split("/", maxsplit=1)
    filepath = path.join(CONTENT_PATH, slug, release['version_tag'] + ".md")

    version = normalize_version(release['version_tag'])

    frontmatter = {
        'date': release['date'].isoformat(),
        'title': f'{slug} Release v{version}',
        'description': f'Changelog entry for {release["repository"]} version {version}, published on {release["date"].strftime("%d %B %Y, %H:%M")}',
        'changelog_entry': {
            'repository': release['repository'],
            'version_tag': release['version_tag'],
            'version': version,
            'url': release['url'],
        },
        'tags': [repo_config['tag']],
    }

    content = "---\n"
    content += "# Generated by scripts/aggregate-changelogs. WARNING: Manual edits to this files will be overwritten.\n"
    content += dump(frontmatter, Dumper=CDumper)
    content += "---\n\n"
    content += release['description']
    content += "\n"

    makedirs(path.dirname(filepath), exist_ok=True)
    with open(filepath, 'w') as outfile:
        outfile.write(content)


if __name__ == "__main__":
    with open(CONFIG_PATH, 'rb') as configfile:
        conf = load(configfile, Loader=CLoader)
    
    if GITHUB_TOKEN == "":
        print("ERROR: GitHub token must be given as 3rd argument")
        sys.exit(1)

    g = Github(GITHUB_TOKEN)
    
    for repo_short in conf['repositories']:
        repo_conf = conf['repositories'][repo_short]

        releases = None

        if repo_short == RELEASES_REPO:
            # TODO: special treatment for releases repo
            print("Special treatment for releases repo %s (TODO)" % repo_short)
            pass

        else:
            # Attempt to get GitHub releases (based on tags in the repo).
            releases = list(get_releases(g, repo_short))

            # Attempt to get releas einfo from CHANGELOG.md.
            changelog = get_changelog_file(g, repo_short)
            
            # Match release tags and changelog versions and
            # enhance release data with descriptions from CHANGELOG.md.
            if changelog is None:
                print(f'INFO: repository {repo_short} has no CHANGELOG.md file.')
            else:
                changelog_entries = {}
                for (version, release) in parse_changelog(changelog, repo_short):
                    v = normalize_version(version)
                    changelog_entries[v] = release
                
                for n in range(len(releases)):
                    v = normalize_version(releases[n]['version_tag'])
                    if v in changelog_entries:
                        releases[n]['description'] = changelog_entries[v]['description']
                        releases[n]['url'] = changelog_entries[v]['url']
                    else:
                        print("WARNING: %s version %s not found in changelog" % (repo_short, v))

        if releases is None:
            continue

        for release in releases:
            generate_release_file(repo_short, repo_conf, release)
